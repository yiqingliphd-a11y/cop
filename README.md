# ==============================================================================
# å®Œæ•´ç‰ˆï¼šå¤šæ¨¡å‹è„‘å½±åƒæ•°æ®åˆ†ææµç¨‹ï¼ˆåŒ…å«æ‰€æœ‰æ¨¡å‹è®­ç»ƒï¼‰
# ==============================================================================

# ğŸ”§ å…³é”®ï¼šåŒ…åŠ è½½é¡ºåº
library(readxl)
library(purrr)
library(tidyr)
library(ggplot2)
library(readr)
library(gridExtra)
library(viridis)
library(pROC)
library(RColorBrewer)
library(randomForest)
library(kernlab)
library(xgboost)
library(klaR)
library(MASS)
library(nnet)
library(gbm)
library(caret)
library(patchwork) # Added for plot combination
library(kernelshap) # Added for SHAP
library(shapviz)    # Added for SHAP plotting
library(dplyr)  # å¿…é¡»æœ€ååŠ è½½

# ==============================================================================
# 0. è¾…åŠ©å‡½æ•°
# ==============================================================================

standardize_colnames <- function(df) {
  new_names <- colnames(df) %>%
    gsub("/", "_", ., fixed = TRUE) %>%
    gsub("[^A-Za-z0-9_.]", "_", .) %>%
    make.unique(sep = "_")
  colnames(df) <- new_names
  return(df)
}

standardize_feature_names <- function(feature_vec) {
  feature_vec %>%
    gsub("/", "_", ., fixed = TRUE) %>%
    gsub("[^A-Za-z0-9_.]", "_", .)
}

validate_features <- function(df, feature_list, dataset_name = "Data") {
  missing_features <- setdiff(feature_list, colnames(df))
  if (length(missing_features) > 0) {
    cat(sprintf("\nâš ï¸ è­¦å‘Š: %s ä¸­ç¼ºå¤±ä»¥ä¸‹ç‰¹å¾:\n", dataset_name))
    cat(paste(head(missing_features, 10), collapse = ", "), "\n")
    return(FALSE)
  }
  cat(sprintf("âœ“ %s: æ‰€æœ‰ %d ä¸ªç‰¹å¾éªŒè¯é€šè¿‡\n", dataset_name, length(feature_list)))
  return(TRUE)
}

calculate_f1 <- function(confusion_matrix_obj) {
  precision <- confusion_matrix_obj$byClass["Pos Pred Value"]
  recall <- confusion_matrix_obj$byClass["Sensitivity"]
  
  if (is.na(precision) || is.na(recall) || (precision + recall) == 0) {
    f1 <- NA
  } else {
    f1 <- 2 * (precision * recall) / (precision + recall)
  }
  return(f1)
}

GLOBAL_FIT_CONTROL <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

# ==============================================================================
# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
# ==============================================================================

clean_and_merge_data <- function(sex_file, vgm_file, vwm_file, vcsf_file,
                                 depth_file, fractal_file, gyrification_file,
                                 thickness_file, path) {
  
  file_list <- list(
    sex = read_excel(paste0(path, sex_file)),
    vgm = read_csv(paste0(path, vgm_file), show_col_types = FALSE),
    vwm = read_csv(paste0(path, vwm_file), show_col_types = FALSE),
    vcsf = read_csv(paste0(path, vcsf_file), show_col_types = FALSE),
    depth = read_csv(paste0(path, depth_file), show_col_types = FALSE),
    fractal = read_csv(paste0(path, fractal_file), show_col_types = FALSE),
    gyrification = read_csv(paste0(path, gyrification_file), show_col_types = FALSE),
    thickness = read_csv(paste0(path, thickness_file), show_col_types = FALSE)
  )
  
  processed_list <- map2(file_list, names(file_list), function(df, name) {
    if (name == "sex") {
      colnames(df)[1] <- "number"
    } else {
      colnames(df)[1] <- "number"
      df <- df %>% rename_with(~ paste(name, .x, sep = "_"), .cols = -number)
    }
    return(df)
  })
  
  merged_data <- reduce(processed_list, full_join, by = "number")
  na_counts <- sapply(merged_data, function(x) sum(is.na(x)))
  cols_to_keep <- names(na_counts[na_counts < nrow(merged_data)])
  merged_data <- merged_data[, cols_to_keep, drop = FALSE]
  merged_data <- standardize_colnames(merged_data)
  
  return(merged_data)
}

analyze_group_differences <- function(data, name_prefix) {
  cat("\n", rep("=", 60), "\n", sep = "")
  cat("å¼€å§‹åˆ†æ ", name_prefix, "\n", sep = "")
  
  label_values <- unique(data$Label)
  if (length(label_values) != 2) stop("Labelåˆ—å¿…é¡»æ°å¥½æœ‰ä¸¤ç»„ã€‚")
  
  continuous_vars <- setdiff(names(data), c("Label", "sex"))
  results_list <- list()
  
  for (i in 1:length(continuous_vars)) {
    var <- continuous_vars[i]
    if (i %% 500 == 0) cat("å·²å¤„ç†", i, "/", length(continuous_vars), "ä¸ªå˜é‡...\n")
    
    tryCatch({
      group1 <- data[[var]][data$Label == label_values[1]]
      group2 <- data[[var]][data$Label == label_values[2]]
      group1 <- group1[!is.na(group1)]; group2 <- group2[!is.na(group2)]
      
      if (length(group1) < 2 || length(group2) < 2) next
      
      t_test <- t.test(group1, group2)
      n1 <- length(group1); n2 <- length(group2)
      pooled_sd <- sqrt(((n1-1)*sd(group1)^2 + (n2-1)*sd(group2)^2) / (n1 + n2 - 2))
      cohens_d <- ifelse(pooled_sd > 0, (mean(group1) - mean(group2)) / pooled_sd, NA)
      
      results_list[[var]] <- data.frame(
        Variable = var, N_Group1 = n1, N_Group2 = n2,
        Group1_Mean = mean(group1), Group2_Mean = mean(group2),
        Mean_Diff = mean(group1) - mean(group2),
        T_pvalue = t_test$p.value, Cohens_d = cohens_d
      )
    }, error = function(e) {})
  }
  
  results_df <- bind_rows(results_list) %>%
    mutate(T_pvalue_adj = p.adjust(T_pvalue, method = "fdr")) %>%
    arrange(T_pvalue)
  
  write_csv(results_df, paste0(base_path, name_prefix, "_group_comparison_results.csv"))
  return(list(results = results_df))
}

# ==============================================================================
# 2. ä¸»æ‰§è¡Œæµç¨‹
# ==============================================================================

base_path <- "C:/Users/19134/OneDrive/Desktop/cop1/"
split_ratio <- 0.7

cat("\n#### A. æ¸…æ´—åˆå¹¶æ•°æ® ####\n")
group1_data_merged <- clean_and_merge_data(
  sex_file = "COP_PD_CI.xlsx",
  vgm_file = "COP_PD_CI_ROI_BN_Atlas_274_combined_Vgm.csv",
  vwm_file = "COP_PD_CI_ROI_BN_Atlas_274_combined_Vwm.csv",
  vcsf_file = "COP_PD_CI_ROI_BN_Atlas_274_combined_Vcsf.csv",
  depth_file = "COP_PD_CI_surf_ROI_aparc_BN_Atlas_depth.csv",
  fractal_file = "COP_PD_CI_surf_ROI_aparc_BN_Atlas_fractaldimension.csv",
  gyrification_file = "COP_PD_CI_surf_ROI_aparc_BN_Atlas_gyrification.csv",
  thickness_file = "COP_PD_CI_surf_ROI_aparc_BN_Atlas_thickness.csv",
  path = base_path
) %>% mutate(Label = "Group1")

group2_data_merged <- clean_and_merge_data(
  sex_file = "COP_CI.xlsx",
  vgm_file = "COP_CI_ROI_BN_Atlas_274_combined_Vgm.csv",
  vwm_file = "COP_CI_ROI_BN_Atlas_274_combined_Vwm.csv",
  vcsf_file = "COP_CI_ROI_BN_Atlas_274_combined_Vcsf.csv",
  depth_file = "COP_CI_surf_ROI_aparc_BN_Atlas_depth.csv",
  fractal_file = "COP_CI_surf_ROI_aparc_BN_Atlas_fractaldimension.csv",
  gyrification_file = "COP_CI_surf_ROI_aparc_BN_Atlas_gyrification.csv",
  thickness_file = "COP_CI_surf_ROI_aparc_BN_Atlas_thickness.csv",
  path = base_path
) %>% mutate(Label = "Group2")

combined_data_all <- bind_rows(group1_data_merged, group2_data_merged) %>%
  dplyr::select(-number)

set.seed(123)
trainIndex <- createDataPartition(combined_data_all$Label, p = split_ratio, list = FALSE)
trainData <- combined_data_all[trainIndex, ]
testData <- combined_data_all[-trainIndex, ]

write.csv(trainData, paste0(base_path, "train_data.csv"), row.names = FALSE)
write.csv(testData, paste0(base_path, "test_data.csv"), row.names = FALSE)

# ==============================================================================
# 3. å‡†å¤‡ç‰¹å¾é›†
# ==============================================================================

F_final_34_vars_original <- c(
  "gyrification_rA35/36r_R", "vgm_Vermis_VIb", "vwm_lPrG_6_4", "vwm_rPoG_4_2",
  "fractal_rlsOccG_R", "vcsf_rCG_7_2", "fractal_lA37dl_L", "vcsf_rINS_6_6",
  "vgm_lOrG_6_1", "vcsf_lIPL_6_5", "vcsf_lpSTS_2_2", "vcsf_lOrG_6_6",
  "vcsf_rLOcC_4_3", "vwm_rPrG_6_4", "vgm_rTha_8_8", "fractal_rIFJ_R",
  "thickness_lA2_L", "gyrification_lA2_L", "thickness_rA11l_R", "gyrification_rA11l_R",
  "vcsf_rPhG_6_3", "vwm_rLOcC_4_4", "depth_lA20iv_L", "vgm_rSFG_7_1",
  "fractal_rA35/36c_R", "fractal_rA23v_R", "gyrification_rA5m_R", "thickness_lA40rd_L",
  "edu", "thickness_rA4tl_R", "vcsf_lCG_7_7", "thickness_lcLinG_L",
  "thickness_lA41/42_L", "depth_rA6m_R"
)

F_final_vars <- c(standardize_feature_names(F_final_34_vars_original), "sex")

trainData_full <- read.csv(paste0(base_path, "train_data.csv"), check.names = FALSE)
testData_full <- read.csv(paste0(base_path, "test_data.csv"), check.names = FALSE)

trainData_full <- standardize_colnames(trainData_full)
testData_full <- standardize_colnames(testData_full)

trainData_final <- trainData_full %>% dplyr::select(Label, all_of(F_final_vars))
testData_final <- testData_full %>% dplyr::select(Label, all_of(F_final_vars))

trainData_final$sex <- factor(trainData_final$sex)
testData_final$sex <- factor(testData_final$sex)
trainData_final$Label <- factor(trainData_final$Label)
testData_final$Label <- factor(testData_final$Label)

# ==============================================================================
# 4. è®­ç»ƒæ‰€æœ‰9ä¸ªæ¨¡å‹
# ==============================================================================

cat("\n### å¼€å§‹è®­ç»ƒ 9 ä¸ªæ¨¡å‹ ###\n")

# 1. Ridge
cat("\n[1/9] è®­ç»ƒ Ridge...\n")
set.seed(42)
ridge_model <- train(Label ~ ., data = trainData_final, method = "glmnet",
                     metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                     preProcess = c("center", "scale"),
                     tuneGrid = expand.grid(alpha = 0, lambda = exp(seq(-5, 2, length.out = 30))))

# 2. Random Forest
cat("[2/9] è®­ç»ƒ Random Forest...\n")
set.seed(42)
rf_model <- train(Label ~ ., data = trainData_final, method = "rf",
                  metric = "ROC", trControl = GLOBAL_FIT_CONTROL, tuneLength = 3)

# 3. SVM
cat("[3/9] è®­ç»ƒ SVM...\n")
set.seed(42)
svm_model <- train(Label ~ ., data = trainData_final, method = "svmRadial",
                   metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                   preProcess = c("center", "scale"), tuneLength = 3)

# 4. KNN
cat("[4/9] è®­ç»ƒ KNN...\n")
set.seed(42)
knn_model <- train(Label ~ ., data = trainData_final, method = "knn",
                   metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                   preProcess = c("center", "scale"), tuneLength = 3)

# 5. XGBoost
cat("[5/9] è®­ç»ƒ XGBoost...\n")
set.seed(42)
xgb_model <- train(Label ~ ., data = trainData_final, method = "xgbTree",
                   metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                   tuneLength = 3, verbose = FALSE)

# 6. Naive Bayes
cat("[6/9] è®­ç»ƒ Naive Bayes...\n")
set.seed(42)
nb_model <- train(Label ~ ., data = trainData_final, method = "naive_bayes",
                  metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                  preProcess = c("center", "scale"), tuneLength = 3)

# 7. LDA
cat("[7/9] è®­ç»ƒ LDA...\n")
set.seed(42)
lda_model <- train(Label ~ ., data = trainData_final, method = "lda",
                   metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                   preProcess = c("center", "scale"))

# 8. NNET
cat("[8/9] è®­ç»ƒ NNET...\n")
set.seed(42)
nnet_model <- train(Label ~ ., data = trainData_final, method = "nnet",
                    metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                    preProcess = c("center", "scale"),
                    tuneGrid = expand.grid(size = c(3, 5), decay = c(0.01, 0.1)),
                    maxit = 200, trace = FALSE)

# 9. GBM
cat("[9/9] è®­ç»ƒ GBM...\n")
set.seed(42)
gbm_model <- train(Label ~ ., data = trainData_final, method = "gbm",
                   metric = "ROC", trControl = GLOBAL_FIT_CONTROL,
                   tuneLength = 3, verbose = FALSE)

cat("\nâœ“ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼\n")

# ==============================================================================
# 5. è¯„ä¼°æ‰€æœ‰æ¨¡å‹ (Train & Test) - [å·²ä¿®æ”¹]
# ==============================================================================

cat("\n### 5. è¯„ä¼°æ¨¡å‹æ€§èƒ½ (Train & Test) ###\n")

models_list <- list(
  Ridge = ridge_model, RF = rf_model, SVM = svm_model, KNN = knn_model,
  XGBoost = xgb_model, NB = nb_model, LDA = lda_model,
  NNET = nnet_model, GBM = gbm_model
)

# å‡†å¤‡ä¸€ä¸ªå‡½æ•°æ¥æå–æ‰€æœ‰æŒ‡æ ‡
calculate_all_metrics <- function(model, data, data_name, model_name) {
  pred <- predict(model, data)
  prob <- predict(model, data, type = "prob")
  cm <- confusionMatrix(pred, data$Label)
  
  positive_class <- levels(data$Label)[2]
  roc_obj <- roc(data$Label, prob[[positive_class]],
                 levels = levels(data$Label), direction = "<", quiet = TRUE)
  
  sens <- cm$byClass["Sensitivity"]
  spec <- cm$byClass["Specificity"]
  
  # ç¡®ä¿ F1 å€¼ä¸º NA æ—¶ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
  f1_val <- cm$byClass["F1"]
  if (is.na(f1_val)) {
    f1_val <- calculate_f1(cm)
  }
  
  metrics <- data.frame(
    Model = model_name,
    Dataset = data_name,
    AUC = as.numeric(auc(roc_obj)),
    Accuracy = cm$overall["Accuracy"],
    Sensitivity = sens,
    Specificity = spec,
    PPV = cm$byClass["Pos Pred Value"],
    NPV = cm$byClass["Neg Pred Value"],
    F1 = f1_val,
    Recall = sens, # Recall is the same as Sensitivity
    Youdens_Index = sens + spec - 1
  )
  return(metrics)
}

# å¾ªç¯è®¡ç®— Train å’Œ Test çš„æŒ‡æ ‡
all_results_list <- list()
# (åœ¨ Section 8 ä¸­å®šä¹‰, ç”¨äºåŒ¹é…æ¨¡å‹åç§°)
display_names_ci <- c("Ridge", "RandomForest", "SVM_Kernel", "KNN",
                      "XGBoost", "NaiveBayes", "LDA", "NeuralNet", "GradientBoosting")

for (i in 1:length(models_list)) {
  model_name <- names(models_list)[i]
  model_display_name <- display_names_ci[i] # ä½¿ç”¨ä¸€è‡´çš„æ˜¾ç¤ºåç§°
  
  cat(sprintf("... è¯„ä¼° %s ...\n", model_display_name))
  model <- models_list[[model_name]]
  
  # è®¡ç®—è®­ç»ƒé›†æŒ‡æ ‡
  all_results_list[[paste(model_name, "train")]] <-
    calculate_all_metrics(model, trainData_final, "Training", model_display_name)
  
  # è®¡ç®—æµ‹è¯•é›†æŒ‡æ ‡
  all_results_list[[paste(model_name, "test")]] <-
    calculate_all_metrics(model, testData_final, "Validation", model_display_name)
}

all_results_df <- bind_rows(all_results_list)

# --- åˆ›å»º Section 9 éœ€è¦çš„æ•°æ®æ¡† ---
# 1. train_performance (ç”¨äºæ–°çš„ Section 9)
train_performance <- all_results_df %>%
  filter(Dataset == "Training") %>%
  dplyr::select(Model, Accuracy, F1, NPV, PPV, Recall, Sensitivity, Specificity, Youdens_Index)

# 2. validation_performance (ç”¨äºæ–°çš„ Section 9)
validation_performance <- all_results_df %>%
  filter(Dataset == "Validation") %>%
  dplyr::select(Model, Accuracy, F1, NPV, PPV, Recall, Sensitivity, Specificity, Youdens_Index)

# --- å…¼å®¹æ—§ä»£ç  (Section 6, 7) ---
# 3. model_comparison (ç”¨äº Section 6, 7)
#    (æˆ‘ä»¬ä» all_results_df é‡æ–°åˆ›å»ºå®ƒï¼Œä½†ä½¿ç”¨åŸå§‹çš„ 'RF', 'SVM' ç­‰åç§°)
model_comparison_orig_names <- bind_rows(lapply(names(models_list), function(name) {
  calculate_all_metrics(models_list[[name]], testData_final, "Validation", name)
}))

model_comparison <- model_comparison_orig_names %>%
  dplyr::select(Model, AUC, Accuracy, Sensitivity, Specificity, PPV, F1) %>%
  rename(Precision = PPV, F1_Score = F1) %>% # æ¢å¤ Section 6 çƒ­åŠ›å›¾æœŸæœ›çš„åç§°
  arrange(desc(AUC))


cat("\nå®Œæ•´æ€§èƒ½å¯¹æ¯”è¡¨ (Validation Set):\n")
print(model_comparison, digits = 4)
write.csv(model_comparison, paste0(base_path, "all_models_performance_with_f1.csv"), row.names = FALSE)

# ==============================================================================
# 6. å¯è§†åŒ– (F1 ä¸ çƒ­åŠ›å›¾)
# ==============================================================================

cat("\n### 6. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ (F1 ä¸ çƒ­åŠ›å›¾) ###\n")

# F1å€¼å¯¹æ¯”å›¾
p_f1 <- ggplot(model_comparison, aes(x = reorder(Model, F1_Score), y = F1_Score, fill = Model)) +
  geom_bar(stat = "identity", alpha = 0.8, show.legend = FALSE) +
  geom_text(aes(label = sprintf("%.4f", F1_Score)), hjust = -0.1, size = 3.5) +
  coord_flip() +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "æ‰€æœ‰æ¨¡å‹ F1 å€¼å¯¹æ¯”", x = "æ¨¡å‹", y = "F1 Score") +
  theme_minimal() +
  ylim(0, max(model_comparison$F1_Score, na.rm = TRUE) * 1.15)

ggsave(paste0(base_path, "f1_score_comparison.png"), p_f1, width = 10, height = 7, dpi = 300)

# çƒ­åŠ›å›¾
heatmap_data <- model_comparison %>%
  dplyr::select(Model, AUC, Accuracy, Sensitivity, Specificity, Precision, F1_Score) %>%
  pivot_longer(cols = -Model, names_to = "Metric", values_to = "Value")

p_heatmap <- ggplot(heatmap_data, aes(x = Metric, y = Model, fill = Value)) +
  geom_tile(color = "white", size = 0.5) +
  geom_text(aes(label = sprintf("%.3f", Value)), color = "black", size = 3) +
  scale_fill_gradient2(low = "#f7fbff", mid = "#6baed6", high = "#08519c",
                       midpoint = 0.8, limits = c(0.5, 1), name = "æŒ‡æ ‡å€¼") +
  labs(title = "æ‰€æœ‰æ¨¡å‹æ€§èƒ½æŒ‡æ ‡çƒ­åŠ›å›¾", x = "æ€§èƒ½æŒ‡æ ‡", y = "æ¨¡å‹") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


ggsave(paste0(base_path, "performance_heatmap_with_f1.png"), p_heatmap, width = 10, height = 7, dpi = 300)

cat("\nâœ“ F1 Score plot saved.\n")
print(p_f1)

cat("\nâœ“ Performance heatmap saved.\n")
print(p_heatmap)

# ==============================================================================
# 7. ROC æ›²çº¿ (åˆ†é¢ä¸ç»„åˆ)
# ==============================================================================

cat("\n### 7. ç”Ÿæˆ ROC æ›²çº¿ (åˆ†é¢ä¸ç»„åˆ) ###\n")

# ç¡®ä¿ models_list å’Œ testData_final å­˜åœ¨
if (!exists("models_list") || !exists("testData_final")) {
  stop("é”™è¯¯: 'models_list' æˆ– 'testData_final' ä¸å­˜åœ¨ã€‚")
}

positive_class <- levels(testData_final$Label)[2]
cat("è®¡ç®— ROC å¯¹è±¡...\n")

roc_list <- list()
auc_values_map <- list()

# ä¸º models_list ä¸­çš„æ¯ä¸ªæ¨¡å‹è®¡ç®— ROC å’Œ AUC
# ä½¿ç”¨ models_list ä¸­çš„åå­— (e.g., "RF", "SVM") ä½œä¸ºåŸºç¡€
for (model_name in names(models_list)) {
  model_obj <- models_list[[model_name]]
  
  tryCatch({
    probabilities <- predict(model_obj, newdata = testData_final, type = "prob")[[positive_class]]
    
    roc_obj <- roc(response = testData_final$Label,
                   predictor = probabilities,
                   levels = levels(testData_final$Label),
                   direction = "<",
                   quiet = TRUE) # å¢åŠ  quiet = TRUE
    
    roc_list[[model_name]] <- roc_obj
    auc_values_map[[model_name]] <- auc(roc_obj)
    
  }, error = function(e) {
    cat(sprintf("è­¦å‘Š: æ— æ³•ä¸ºæ¨¡å‹ '%s' è®¡ç®— ROC: %s\n", model_name, e$message))
  })
}

# --- 7a. å‡†å¤‡ç”¨äºåˆ†é¢å›¾çš„æ•°æ®æ¡† ---
display_names_roc <- c(
  "Ridge" = "Ridge", "RF" = "Random Forest", "SVM" = "SVM (RBF)", "KNN" = "KNN",
  "XGBoost" = "XGBoost", "NB" = "Naive Bayes", "LDA" = "LDA", "NNET" = "NNET", "GBM" = "GBM"
)

roc_data_facet <- map_dfr(names(roc_list), function(model_name) {
  roc_obj <- roc_list[[model_name]]
  coords_df <- coords(roc_obj, "all", ret = c("threshold", "specificity", "sensitivity"), transpose = FALSE)
  
  # ä½¿ç”¨æ˜ å°„çš„æ˜¾ç¤ºåç§°
  display_name <- ifelse(model_name %in% names(display_names_roc), display_names_roc[model_name], model_name)
  
  coords_df$Model <- sprintf("%s (AUC = %.4f)", display_name, auc_values_map[[model_name]])
  return(coords_df)
})

roc_data_facet <- roc_data_facet %>%
  mutate(FalsePositiveRate = 1 - specificity) %>%
  mutate(Model = factor(Model, levels = map_chr(
    names(sort(unlist(auc_values_map), decreasing=TRUE)),
    function(name) {
      display_name <- ifelse(name %in% names(display_names_roc), display_names_roc[name], name)
      sprintf("%s (AUC = %.4f)", display_name, auc_values_map[[name]])
    }
  )))

cat("ç”Ÿæˆåˆ†é¢ ROC æ›²çº¿å›¾...\n")
p_roc_facet <- ggplot(roc_data_facet, aes(x = FalsePositiveRate, y = sensitivity)) +
  geom_line(aes(color = Model), size = 1) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "grey50") +
  facet_wrap(~ Model, nrow = 3) +
  theme_bw() +
  scale_color_discrete(guide = "none") +
  labs(
    title = "ä¹æ¨¡å‹ ROC æ›²çº¿å¯¹æ¯” (åˆ†é¢å›¾, TestData)",
    x = "1 - Specificity (False Positive Rate)",
    y = "Sensitivity (True Positive Rate)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12),
    strip.text = element_text(size = 9)
  )

ggsave(paste0(base_path, "combined_roc_curves_9models_facet.png"), plot = p_roc_facet, width = 12, height = 10, dpi = 300)
cat("âœ“ åˆ†é¢ ROC æ›²çº¿å›¾å·²ä¿å­˜ã€‚\n")
print(p_roc_facet)


# --- 7b. å‡†å¤‡ç”¨äºå½©è‰²å¯¹æ¯”å›¾çš„æ•°æ®æ¡† ---
# æŒ‰ AUC é™åºæ’åº
ordered_script_names <- names(sort(unlist(auc_values_map), decreasing = TRUE))
roc_list_ordered <- roc_list[ordered_script_names]

roc_data_colored <- map_dfr(names(roc_list_ordered), function(model_name) {
  roc_obj <- roc_list_ordered[[model_name]]
  coords_df <- coords(roc_obj, "all", ret = c("specificity", "sensitivity"), transpose = FALSE)
  
  display_name <- ifelse(model_name %in% names(display_names_roc), display_names_roc[model_name], model_name)
  coords_df$ModelLabel <- sprintf("%s (AUC = %.4f)", display_name, auc_values_map[[model_name]])
  
  return(coords_df)
})

roc_data_colored <- roc_data_colored %>%
  mutate(FalsePositiveRate = 1 - specificity) %>%
  mutate(ModelLabel = factor(ModelLabel, levels = unique(ModelLabel))) # ä¿æŒ AUC æ’åº

cat("ç”Ÿæˆå½©è‰² ROC æ›²çº¿å›¾ (æ‰€æœ‰æ¨¡å‹ä¸åŒé¢œè‰²)...\n")
color_palette_roc <- brewer.pal(n = max(3, length(roc_list)), name = "Paired") # è‡³å°‘è¦3ç§é¢œè‰²

p_roc_colored <- ggplot(roc_data_colored,
                        aes(x = FalsePositiveRate, y = sensitivity,
                            color = ModelLabel,
                            group = ModelLabel)) +
  geom_line(size = 0.8, alpha = 0.9) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "grey50") +
  scale_color_manual(values = color_palette_roc, name = "æ¨¡å‹ (AUC)") +
  theme_bw() +
  ggtitle("ä¹æ¨¡å‹ ROC æ›²çº¿å¯¹æ¯” (TestData)") +
  xlab("1 - Specificity (False Positive Rate)") +
  ylab("Sensitivity (True Positive Rate)") +
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title = element_text(size = 12),
        legend.title = element_text(size = 11),
        legend.text = element_text(size = 9),
        legend.position = "right",
        legend.key.size = unit(0.8, "lines"))

ggsave(paste0(base_path, "combined_roc_curves_9models_colored.png"), plot = p_roc_colored, width = 11, height = 8, dpi = 300)
cat("âœ“ å½©è‰² ROC æ›²çº¿å›¾å·²ä¿å­˜ã€‚\n")
print(p_roc_colored)


# ==============================================================================
# 8. AUC 95% CI å¯¹æ¯”å›¾ (Train vs Test)
# ==============================================================================
# æ­¤éƒ¨åˆ†æ”¹ç¼–è‡ªç”¨æˆ·æä¾›çš„ #39.
# å®ƒä½¿ç”¨ `models_list` ä¸­çš„æ¨¡å‹, å¹¶åŒ¹é… #39 ä¸­å®šä¹‰çš„æ˜¾ç¤ºåç§°é¡ºåº

cat("\n### 8. ç»˜åˆ¶ Train/Validation AUC with 95% CI ###\n")

# ç¡®ä¿ trainData_final ä¹Ÿå­˜åœ¨
if (!exists("trainData_final")) {
  stop("é”™è¯¯: 'trainData_final' ä¸å­˜åœ¨ (CI å›¾éœ€è¦)ã€‚")
}

# è¿™äº›æ˜¯ç”¨äºç»˜å›¾çš„æ˜¾ç¤ºåç§°, é¡ºåºå¿…é¡»ä¸ 'models_list' ä¸€è‡´
display_names_ci <- c("Ridge", "RandomForest", "SVM_Kernel", "KNN",
                      "XGBoost", "NaiveBayes", "LDA", "NeuralNet", "GradientBoosting")

# æ£€æŸ¥åç§°åˆ—è¡¨é•¿åº¦æ˜¯å¦åŒ¹é…
if (length(display_names_ci) != length(models_list)) {
  stop("é”™è¯¯: CIå›¾çš„ 'display_names_ci' åˆ—è¡¨é•¿åº¦ä¸ 'models_list' ä¸åŒ¹é…ã€‚")
}

script_model_names <- names(models_list) # e.g., "Ridge", "RF", "SVM", ...

cat("Calculating ROC, AUC, and 95% CI (using bootstrap)...\n")
auc_ci_results <- list()
n_bootstrap <- 2000 # å‡å°‘ bootstrap æ¬¡æ•°ä»¥åŠ å¿«é€Ÿåº¦, 2000 ä»ç„¶å¾ˆç¨³å¥

for (i in 1:length(script_model_names)) {
  
  script_name <- script_model_names[i]
  model_display_name <- display_names_ci[i] # ä½¿ç”¨ #39 ä¸­çš„ç›®æ ‡æ˜¾ç¤ºåç§°
  
  model_obj <- models_list[[script_name]]
  
  # Validation (Test) Set
  prob_val <- predict(model_obj, newdata = testData_final, type = "prob")[[positive_class]]
  roc_val <- roc(response = testData_final$Label, predictor = prob_val,
                 levels = levels(testData_final$Label), direction = "<", quiet = TRUE)
  ci_val <- ci.auc(roc_val, method = "bootstrap", boot.n = n_bootstrap, progress = "none")
  
  # Training Set
  prob_train <- predict(model_obj, newdata = trainData_final, type = "prob")[[positive_class]]
  roc_train <- roc(response = trainData_final$Label, predictor = prob_train,
                   levels = levels(trainData_final$Label), direction = "<", quiet = TRUE)
  ci_train <- ci.auc(roc_train, method = "bootstrap", boot.n = n_bootstrap, progress = "none")
  
  # å­˜å‚¨ç»“æœ (ä½¿ç”¨ display_name ä½œä¸º key)
  auc_ci_results[[model_display_name]] <- list(
    Train_AUC = as.numeric(ci_train[2]), Train_LowerCI = as.numeric(ci_train[1]), Train_UpperCI = as.numeric(ci_train[3]),
    Validation_AUC = as.numeric(ci_val[2]), Validation_LowerCI = as.numeric(ci_val[1]), Validation_UpperCI = as.numeric(ci_val[3])
  )
  
  cat(sprintf("   - %s: Train AUC=%.3f (%.3f-%.3f), Val AUC=%.3f (%.3f-%.3f)\n",
              model_display_name,
              auc_ci_results[[model_display_name]]$Train_AUC, auc_ci_results[[model_display_name]]$Train_LowerCI, auc_ci_results[[model_display_name]]$Train_UpperCI,
              auc_ci_results[[model_display_name]]$Validation_AUC, auc_ci_results[[model_display_name]]$Validation_LowerCI, auc_ci_results[[model_display_name]]$Validation_UpperCI))
}

# --- å‡†å¤‡ç”¨äº CI å›¾çš„æ•°æ®æ¡† ---
plot_data_ci <- map_dfr(names(auc_ci_results), ~{
  data.frame(
    Model = .x,
    Train_AUC = auc_ci_results[[.x]]$Train_AUC,
    Train_LowerCI = auc_ci_results[[.x]]$Train_LowerCI,
    Train_UpperCI = auc_ci_results[[.x]]$Train_UpperCI,
    Validation_AUC = auc_ci_results[[.x]]$Validation_AUC,
    Validation_LowerCI = auc_ci_results[[.x]]$Validation_LowerCI,
    Validation_UpperCI = auc_ci_results[[.x]]$Validation_UpperCI
  )
}) %>%
  mutate(
    Train_Label = sprintf("%.3f (%.3f-%.3f)", Train_AUC, Train_LowerCI, Train_UpperCI),
    Validation_Label = sprintf("%.3f (%.3f-%.3f)", Validation_AUC, Validation_LowerCI, Validation_UpperCI)
  ) %>%
  arrange(Validation_AUC) %>%
  mutate(Model = factor(Model, levels = Model))

# ä¸ºæ¯ä¸ªæ¨¡å‹åˆ†é…ä¸åŒé¢œè‰²
color_palette_ci <- c("#3B9AB2", "#78B7C5", "#EBCC2A", "#E1AF00", "#F21A00",
                      "#E85D04", "#9C964A", "#FDA333", "#C05C55")
plot_data_ci <- plot_data_ci %>%
  mutate(Model_Color = color_palette_ci[1:n()])

# --- åˆ›å»º CI å›¾ ---
cat("\nGenerating AUC (95% CI) plots...\n")

# ã€ä¿®æ­£ã€‘ä½¿ç”¨ ggplot2::margin é¿å…å‡½æ•°å†²çª
example_theme <- theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 13, face = "bold",
                              margin = ggplot2::margin(b = 10)),
    plot.background = element_rect(fill = "white", color = NA),
    panel.background = element_rect(fill = "white", color = NA),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_text(size = 10, color = "black"),
    axis.text.y = element_text(size = 10, color = "black", hjust = 1,
                               margin = ggplot2::margin(r = 5)),
    panel.grid.major = element_line(color = "gray90", linewidth = 0.3),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5),
    plot.margin = ggplot2::margin(5, 10, 5, 10),
    legend.position = "none"
  )

# è®­ç»ƒé›†å›¾
plot_train_exact <- ggplot(plot_data_ci, aes(y = Model)) +
  geom_segment(aes(x = Train_LowerCI, xend = Train_UpperCI,
                   y = Model, yend = Model, color = Model),
               linewidth = 1.5, show.legend = FALSE) +
  geom_point(aes(x = Train_AUC, color = Model, fill = Model),
             size = 4, shape = 23, stroke = 0.5, show.legend = FALSE) +
  geom_text(aes(x = (Train_LowerCI + Train_UpperCI) / 2, label = Train_Label),
            vjust = -0.8, size = 3, color = "black", fontface = "plain") +
  scale_color_manual(values = setNames(plot_data_ci$Model_Color, plot_data_ci$Model)) +
  scale_fill_manual(values = setNames(plot_data_ci$Model_Color, plot_data_ci$Model)) +
  scale_x_continuous(
    limits = c(0.5, 1.05),
    breaks = seq(0.5, 1.0, 0.05),
    expand = expansion(mult = c(0.01, 0.01))
  ) +
  labs(title = "Train") +
  example_theme +
  theme(
    plot.title = element_text(hjust = 0.5, size = 13, face = "bold",
                              margin = ggplot2::margin(t = 3, b = 8, l = 0, r = 0)), # <--- ä¿®æ­£
    plot.background = element_rect(fill = "white", color = NA)
  )

# éªŒè¯é›† (Test) å›¾
plot_validation_exact <- ggplot(plot_data_ci, aes(y = Model)) +
  geom_segment(aes(x = Validation_LowerCI, xend = Validation_UpperCI,
                   y = Model, yend = Model, color = Model),
               linewidth = 1.5) +
  geom_point(aes(x = Validation_AUC, color = Model, fill = Model),
             size = 4, shape = 23, stroke = 0.5) +
  geom_text(aes(x = (Validation_LowerCI + Validation_UpperCI) / 2, label = Validation_Label),
            vjust = -0.8, size = 3, color = "black", fontface = "plain") +
  scale_color_manual(
    values = setNames(plot_data_ci$Model_Color, plot_data_ci$Model),
    name = "Model"
  ) +
  scale_fill_manual(
    values = setNames(plot_data_ci$Model_Color, plot_data_ci$Model),
    name = "Model"
  ) +
  scale_x_continuous(
    limits = c(0.5, 1.05),
    breaks = seq(0.5, 1.0, 0.05),
    expand = expansion(mult = c(0.01, 0.01))
  ) +
  labs(title = "Test") +
  example_theme +
  theme(
    plot.title = element_text(hjust = 0.5, size = 13, face = "bold",
                              margin = ggplot2::margin(t = 5, b = 10)), # <--- ä¿®æ­£
    plot.title.position = "plot",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = "right",
    legend.title = element_text(size = 11, face = "bold", margin = ggplot2::margin(b = 8)), # <--- ä¿®æ­£
    legend.text = element_text(size = 10),
    legend.key.size = unit(0.8, "cm"),
    legend.spacing.y = unit(0.3, "cm"),
    legend.background = element_rect(fill = "white", color = "gray70", linewidth = 0.3),
    legend.margin = ggplot2::margin(5, 5, 5, 5) # <--- ä¿®æ­£
  ) +
  guides(color = guide_legend(
    override.aes = list(
      shape = 23,
      size = 4,
      stroke = 0.5,
      linewidth = 1.5
    )
  ))

# --- ç»„åˆå¹¶ä¿å­˜ CI å›¾ ---
cat("\nCombining CI plots side-by-side...\n")

combined_plot_exact <- (plot_train_exact + plot_validation_exact) +
  plot_layout(widths = c(1, 1)) +
  plot_annotation(
    caption = "AUC Score (95% CI)",
    theme = theme(
      plot.caption = element_text(hjust = 0.5, size = 12, face = "bold",
                                  margin = ggplot2::margin(t = 8), color = "black") # <--- ä¿®æ­£
    )
  ) &
  theme(
    plot.title = element_text(
      hjust = 0.5, size = 13, face = "bold",
      margin = ggplot2::margin(t = 5, b = 8, l = 5, r = 5) # <--- ä¿®æ­£
    ),
    plot.background = element_rect(fill = "gray88", color = "black", linewidth = 0.5),
    plot.margin = ggplot2::margin(8, 10, 5, 10) # <--- ä¿®æ­£
  )

output_file_ci <- paste0(base_path, "auc_comparison_train_test_ci.png")
ggsave(output_file_ci, plot = combined_plot_exact,
       width = 14, height = 7, dpi = 300, bg = "white")
cat(sprintf("\nâœ“ AUC (95%% CI) plot saved to: %s\n", output_file_ci))

print(combined_plot_exact)

# ==============================================================================
# 9. Plot Performance Metrics Comparison - Matching AUC Plot Style (æ–°æ·»åŠ )
# ==============================================================================

cat("\n### 9. ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”å›¾ (åŒ¹é…AUCé£æ ¼) ###\n")

# --- 1. æ£€æŸ¥æ–°ç”Ÿæˆçš„æ•°æ®æ˜¯å¦å­˜åœ¨ ---
if (!exists("train_performance") || !exists("validation_performance")) {
  stop("é”™è¯¯: 'train_performance' æˆ– 'validation_performance' æ•°æ®æ¡†æœªæ‰¾åˆ°ã€‚")
}
cat("ä½¿ç”¨å·²ç”Ÿæˆçš„ performance metrics...\n")

# --- 2. è½¬æ¢ä¸ºé•¿æ ¼å¼ ---
train_long <- train_performance %>%
  pivot_longer(cols = -Model, names_to = "Metric", values_to = "Value") %>%
  mutate(Dataset = "Training")

validation_long <- validation_performance %>%
  pivot_longer(cols = -Model, names_to = "Metric", values_to = "Value") %>%
  mutate(Dataset = "Validation")

performance_data_actual <- bind_rows(train_long, validation_long) %>%
  filter(!is.na(Value)) %>%
  mutate(
    Metric = factor(Metric, levels = c("Accuracy", "F1", "NPV", "PPV",
                                       "Recall", "Sensitivity", "Specificity",
                                       "Youdens_Index")),
    Metric_Label = case_when(
      Metric == "Youdens_Index" ~ "Youden's Index",
      Metric == "PPV" ~ "Precision (PPV)",
      Metric == "NPV" ~ "NPV",
      Metric == "Recall" ~ "Recall (Sens)",
      TRUE ~ as.character(Metric)
    ),
    Dataset = factor(Dataset, levels = c("Training", "Validation"))
  ) %>%
  # æŒ‰ Validation Accuracy æ’åº
  mutate(Model = factor(Model, levels = validation_performance$Model[
    order(validation_performance$Accuracy, decreasing = TRUE)]))

# --- 3. å®šä¹‰é¢œè‰² ---
# (ä½¿ç”¨ Section 8 ä¸­å®šä¹‰çš„ CI è°ƒè‰²æ¿)
model_colors <- color_palette_ci
names(model_colors) <- levels(performance_data_actual$Model)

# --- 4. å®šä¹‰ä¸»é¢˜ (ä½¿ç”¨ ggplot2::margin ä¿®æ­£) ---
auc_matching_theme <- theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 13, face = "bold",
                              margin = ggplot2::margin(t = 5, b = 8, l = 5, r = 5)),
    plot.background = element_rect(fill = "gray88", color = "black", linewidth = 0.5),
    panel.background = element_rect(fill = "white", color = NA),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "black"),
    axis.text.y = element_text(size = 10, color = "black"),
    panel.grid.major = element_line(color = "gray90", linewidth = 0.3),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5),
    plot.margin = ggplot2::margin(8, 10, 5, 10),
    legend.position = "none"
  )

# --- 5. è®¡ç®—Yè½´èŒƒå›´ ---
min_y_val <- floor(min(performance_data_actual$Value, na.rm = TRUE) * 20) / 20
max_y_val <- 1.05

# --- 6. åˆ›å»ºè®­ç»ƒé›†å›¾ ---
cat("\nGenerating Training plot...\n")
plot_train_matching <- performance_data_actual %>%
  filter(Dataset == "Training") %>%
  ggplot(aes(x = Metric_Label, y = Value, group = Model, color = Model)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3, shape = 19) +
  scale_color_manual(values = model_colors) +
  scale_y_continuous(
    limits = c(min_y_val, max_y_val),
    breaks = seq(min_y_val, 1.0, 0.05),
    expand = expansion(mult = c(0.01, 0.01))
  ) +
  labs(title = "Train") +
  auc_matching_theme

# --- 7. åˆ›å»ºéªŒè¯é›†å›¾ (å¸¦å›¾ä¾‹) ---
cat("Generating Validation plot...\n")
plot_validation_matching <- performance_data_actual %>%
  filter(Dataset == "Validation") %>%
  ggplot(aes(x = Metric_Label, y = Value, group = Model, color = Model)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3, shape = 19) +
  scale_color_manual(values = model_colors, name = "Model") +
  scale_y_continuous(
    limits = c(min_y_val, max_y_val),
    breaks = seq(min_y_val, 1.0, 0.05),
    expand = expansion(mult = c(0.01, 0.01))
  ) +
  labs(title = "Test") +
  auc_matching_theme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 11, face = "bold", margin = ggplot2::margin(b = 8)),
    legend.text = element_text(size = 10),
    legend.key.size = unit(0.8, "cm"),
    legend.spacing.y = unit(0.3, "cm"),
    legend.background = element_rect(fill = "white", color = "gray70", linewidth = 0.3),
    legend.margin = ggplot2::margin(5, 5, 5, 5)
  )

# --- 8. ç»„åˆå›¾ ---
cat("\nCombining plots side-by-side...\n")

combined_plot_matching <- (plot_train_matching + plot_validation_matching) +
  plot_layout(widths = c(1, 1)) + # 1:1æ¯”ä¾‹,å¤§å°ä¸€è‡´
  plot_annotation(
    caption = "Performance Metrics Comparison",
    theme = theme(
      plot.caption = element_text(hjust = 0.5, size = 12, face = "bold",
                                  margin = ggplot2::margin(t = 8), color = "black")
    )
  ) &
  theme(
    plot.title = element_text(
      hjust = 0.5, size = 13, face = "bold",
      margin = ggplot2::margin(t = 5, b = 8, l = 5, r = 5)
    ),
    plot.background = element_rect(fill = "gray88", color = "black", linewidth = 0.5),
    plot.margin = ggplot2::margin(8, 10, 5, 10)
  )

# --- 9. ä¿å­˜ç»„åˆå›¾ ---
output_file <- paste0(base_path, "performance_metrics_auc_style.png")
ggsave(output_file, plot = combined_plot_matching,
       width = 14, height = 7, dpi = 300, bg = "white")
cat(sprintf("\nPerformance metrics plot (AUC style) saved to: %s\n", output_file))

print(combined_plot_matching)

cat("\nPerformance metrics plot generated successfully.\n")

# ==============================================================================
# 10. SHAP åˆ†æ (æœ€ä½³æ¨¡å‹)
# ==============================================================================

cat("\n### 10. SHAP åˆ†æ (æœ€ä½³æ¨¡å‹) ###\n")

# --- 1. è¯†åˆ«æœ€ä½³æ¨¡å‹ ---
# (åŸºäº model_comparison_orig_namesï¼Œå› ä¸ºå®ƒæœ‰åŸå§‹æ¨¡å‹åç§° "RF", "SVM" ç­‰)
if (!exists("model_comparison_orig_names")) {
  stop("é”™è¯¯: 'model_comparison_orig_names' æœªåœ¨ Section 5 ä¸­å®šä¹‰ã€‚")
}
best_model_name <- model_comparison_orig_names %>%
  arrange(desc(AUC)) %>%
  head(1) %>%
  pull(Model)

best_model_obj <- models_list[[best_model_name]]

cat(sprintf("è¯†åˆ«å‡ºçš„æœ€ä½³æ¨¡å‹ (åŸºäºAUC): %s\n", best_model_name))
cat("å‡†å¤‡ SHAP åˆ†ææ•°æ®...\n")

# --- 2. å‡†å¤‡æ•°æ® ---
# ç¡®ä¿ Label åˆ—è¢«ç§»é™¤
explainer_data <- trainData_final %>% dplyr::select(-Label)
eval_data <- testData_final %>% dplyr::select(-Label)

# SHAP éœ€è¦æ•°å€¼å‹æ•°æ® (å°† 'sex' å› å­è½¬æ¢ä¸º 0/1)
# æ³¨æ„: caret çš„ preProcess = c("center", "scale") ä¸ä¼šè½¬æ¢å› å­
explainer_data <- explainer_data %>%
  mutate(sex = ifelse(sex == levels(trainData_final$sex)[1], 0, 1))
eval_data <- eval_data %>%
  mutate(sex = ifelse(sex == levels(trainData_final$sex)[1], 0, 1))

# --- 3. å®šä¹‰é¢„æµ‹å‡½æ•° (wrapper) ---
# SHAP éœ€è¦ä¸€ä¸ªåªè¿”å› positive_class æ¦‚ç‡çš„å‡½æ•°
positive_class_shap <- levels(trainData_final$Label)[2]

# [ä¿®æ”¹] è°ƒæ•´ pred_wrapper ä»¥ç›´æ¥ä½¿ç”¨åº•å±‚æ¨¡å‹ (ä¾‹å¦‚ ksvm)
pred_wrapper <- function(model, newdata) {
  # model ç°åœ¨æ˜¯åº•å±‚æ¨¡å‹, ä¾‹å¦‚ ksvm
  
  # [æœ€ç»ˆä¿®æ­£] ä¸å†å°† sex è½¬å›å› å­ï¼Œç›´æ¥ä½¿ç”¨æ•°å€¼å‹
  # if ("sex" %in% colnames(newdata)) {
  #    newdata$sex <- factor(
  #      newdata$sex,
  #      levels = c(0, 1),
  #      labels = levels(trainData_final$sex) # ä½¿ç”¨åŸå§‹è®­ç»ƒæ•°æ®çš„å› å­æ°´å¹³
  #    )
  # }
  
  
  # è°ƒç”¨ç‰¹å®šäºæ¨¡å‹çš„ predict æ–¹æ³•
  # å¯¹äº kernlab::ksvm (æ¥è‡ª svmRadial)
  if (inherits(model, "ksvm")) {
    # kernlab è¿”å›ä¸€ä¸ªçŸ©é˜µï¼Œåˆ—åæ˜¯ç±»åˆ«æ ‡ç­¾
    probs_matrix <- tryCatch(
      kernlab::predict(model, newdata = newdata, type = "probabilities"),
      error = function(e) {
        cat("kernlab::predict é”™è¯¯: ", e$message, "\n")
        cat("æ£€æŸ¥ newdata çš„åˆ—åå’Œç±»å‹æ˜¯å¦ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ã€‚\n")
        # æ‰“å° newdata ç»“æ„ä»¥ä¾›è°ƒè¯•
        cat("--- newdata structure in ksvm error ---\n")
        print(str(newdata))
        cat("--- End newdata structure ---\n")
        NULL # è¿”å› NULL è¡¨ç¤ºå¤±è´¥
      }
    )
    if (is.null(probs_matrix) || !(positive_class_shap %in% colnames(probs_matrix))) {
      cat("é”™è¯¯: æ— æ³•ä» kernlab::predict è·å– positive_class_shap çš„æ¦‚ç‡ã€‚\n")
      cat("æ£€æŸ¥ positive_class_shap æ˜¯å¦æ­£ç¡®: ", positive_class_shap, "\n")
      if (!is.null(probs_matrix)) {
        cat("æ£€æŸ¥ probs_matrix åˆ—å: ", paste(colnames(probs_matrix), collapse=", "), "\n")
      } else {
        cat("probs_matrix ä¸º NULLã€‚\n")
      }
      # è¿”å›ä¸€ä¸ªé”™è¯¯å€¼æˆ–åœæ­¢ï¼Œè¿™é‡Œè¿”å› NA å‘é‡
      return(rep(NA_real_, nrow(newdata)))
    }
    # è¿”å› positive class çš„æ¦‚ç‡å‘é‡
    return(probs_matrix[, positive_class_shap])
    
  } else if (inherits(model, "randomForest")) {
    # randomForest çš„ predict type="prob"
    # [ä¿®æ­£] RF ä¹Ÿéœ€è¦å› å­ sex
    if ("sex" %in% colnames(newdata)) {
      newdata$sex <- factor(
        newdata$sex,
        levels = c(0, 1),
        labels = levels(trainData_final$sex)
      )
    }
    probs_matrix <- predict(model, newdata = newdata, type = "prob")
    if (is.null(probs_matrix) || !(positive_class_shap %in% colnames(probs_matrix))) {
      # å¤„ç†é”™è¯¯...
      return(rep(NA_real_, nrow(newdata)))
    }
    return(probs_matrix[, positive_class_shap])
    
  } else if (inherits(model, "xgb.Booster")) {
    # xgboost éœ€è¦ dmatrixï¼Œå¹¶ä¸”ä¸éœ€è¦å› å­è½¬æ¢
    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼å‹
    numeric_newdata <- data.matrix(newdata)
    xgb_newdata <- xgboost::xgb.DMatrix(data = numeric_newdata)
    probs_vector <- predict(model, newdata = xgb_newdata)
    # xgboost predict ç›´æ¥è¿”å› positive class çš„æ¦‚ç‡ (å¦‚æœæ˜¯äºŒåˆ†ç±»)
    return(probs_vector)
    
  } else if (inherits(model, "naive_bayes")) {
    # naivebayes åŒ…å¯èƒ½éœ€è¦å› å­ï¼Œä¹Ÿå¯èƒ½å¤„ç†æ•°å€¼ï¼Œå–å†³äºè®­ç»ƒæ–¹å¼
    # å°è¯•å› å­è½¬æ¢
    if ("sex" %in% colnames(newdata)) {
      newdata$sex <- factor(
        newdata$sex,
        levels = c(0, 1),
        labels = levels(trainData_final$sex)
      )
    }
    probs_matrix <- predict(model, newdata = newdata, type = "prob")
    if (is.null(probs_matrix) || !(positive_class_shap %in% colnames(probs_matrix))) {
      # å¤„ç†é”™è¯¯...
      return(rep(NA_real_, nrow(newdata)))
    }
    return(probs_matrix[, positive_class_shap])
    
  } else if (inherits(model, "lda")) {
    # MASS::lda é€šå¸¸å¤„ç†æ•°å€¼å‹æ•°æ®
    pred_obj <- predict(model, newdata = newdata)
    # lda çš„ posterior çŸ©é˜µ
    probs_matrix <- pred_obj$posterior
    if (is.null(probs_matrix) || !(positive_class_shap %in% colnames(probs_matrix))) {
      # å¤„ç†é”™è¯¯...
      return(rep(NA_real_, nrow(newdata)))
    }
    return(probs_matrix[, positive_class_shap])
    
  } else if (inherits(model, "nnet.formula") || inherits(model, "nnet")) {
    # nnet åŒ…ï¼Œé€šå¸¸å¤„ç†æ•°å€¼å‹
    probs_matrix <- predict(model, newdata = newdata, type = "raw") # nnet ä½¿ç”¨ raw
    # nnet å¯èƒ½è¿”å›å•åˆ—æˆ–å¤šåˆ—ï¼Œå–å†³äºç±»åˆ«æ•°
    if (ncol(probs_matrix) == 1) {
      # å‡è®¾å•åˆ—æ˜¯ positive class
      return(as.vector(probs_matrix))
    } else if (positive_class_shap %in% colnames(probs_matrix)){
      return(probs_matrix[, positive_class_shap])
    } else {
      # å¤„ç†é”™è¯¯...
      return(rep(NA_real_, nrow(newdata)))
    }
    
  } else if (inherits(model, "gbm.object")) {
    # gbm åŒ…ï¼Œé€šå¸¸å¤„ç†æ•°å€¼å‹
    # gbm éœ€è¦æŒ‡å®š n.trees
    best_iter <- model$n.trees # æˆ–è€… caret ç»“æœä¸­çš„æœ€ä½³è¿­ä»£æ¬¡æ•°
    probs_vector <- predict(model, newdata = newdata, n.trees = best_iter, type = "response")
    # gbm predict type="response" è¿”å› positive class æ¦‚ç‡
    return(probs_vector)
    
  } else if (inherits(model, "glmnet")) {
    # glmnet (Ridge/Lasso)ï¼Œéœ€è¦æ•°å€¼çŸ©é˜µ
    # éœ€è¦æŒ‡å®š lambda å€¼ï¼Œé€šå¸¸æ˜¯ caret æ‰¾åˆ°çš„æœ€ä½³å€¼
    best_lambda <- model$lambdaOpt # æˆ–è€…ä» caret æ¨¡å‹è·å–
    # ç¡®ä¿è¾“å…¥æ˜¯çŸ©é˜µ
    numeric_newdata <- data.matrix(newdata)
    probs_matrix <- predict(model, newx = numeric_newdata, s = best_lambda, type = "response")
    # glmnet family="binomial" type="response" è¿”å› positive class æ¦‚ç‡
    return(as.vector(probs_matrix))
    
  } else if (inherits(model, "knn3")) {
    # caret çš„ knnï¼Œé€šå¸¸å¤„ç†æ•°å€¼å‹
    probs_matrix <- predict(model, newdata = newdata, type = "prob")
    if (is.null(probs_matrix) || !(positive_class_shap %in% colnames(probs_matrix))) {
      # å¤„ç†é”™è¯¯...
      return(rep(NA_real_, nrow(newdata)))
    }
    return(probs_matrix[, positive_class_shap])
  }
  # ... å…¶ä»–æ¨¡å‹ç±»å‹ ...
  
  else {
    stop("æœªçŸ¥çš„æ¨¡å‹ç±»å‹ï¼Œæ— æ³•åœ¨ pred_wrapper ä¸­å¤„ç†: ", class(model)[1])
  }
}



cat("å¼€å§‹è®¡ç®— SHAP å€¼... (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)\n")

# --- 4. è®¡ç®— SHAP å€¼ ---
# ä½¿ç”¨è¾ƒå°çš„ nsim (e.g., 50) ä»¥åŠ å¿«é€Ÿåº¦, 100-200 æ›´ç¨³å®š
# ä½¿ç”¨ explainer_data (è®­ç»ƒé›†) ä½œä¸ºèƒŒæ™¯æ•°æ®
# ä½¿ç”¨ eval_data (æµ‹è¯•é›†) ä½œä¸ºè¦è§£é‡Šçš„æ•°æ®

# è°ƒè¯•ä¿¡æ¯: æ£€æŸ¥æ•°æ®å’Œå‡½æ•°
cat("--- SHAP è°ƒè¯•ä¿¡æ¯ å¼€å§‹ ---\n")
cat("æœ€ä½³æ¨¡å‹å¯¹è±¡ (åŸå§‹ caret train å¯¹è±¡):\n")
print(class(best_model_obj))
cat("ä½¿ç”¨çš„åº•å±‚æ¨¡å‹å¯¹è±¡ (best_model_obj$finalModel):\n")
underlying_model <- best_model_obj$finalModel
print(class(underlying_model))

cat("\nè§£é‡Šå™¨èƒŒæ™¯æ•°æ® (explainer_data) ç»“æ„ (ç»™ kernelshap çš„è¾“å…¥):\n")
print(str(explainer_data)) # åº”è¯¥æ˜¯æ•°å€¼å‹ï¼ŒåŒ…æ‹¬ sex=0/1

cat("\nè¯„ä¼°æ•°æ® (eval_data) ç»“æ„ (ç»™ kernelshap çš„è¾“å…¥):\n")
print(str(eval_data)) # åº”è¯¥æ˜¯æ•°å€¼å‹ï¼ŒåŒ…æ‹¬ sex=0/1

cat("\næµ‹è¯• pred_wrapper å‡½æ•° (ä½¿ç”¨åº•å±‚æ¨¡å‹):\n")
test_pred_input <- head(eval_data) # å–å‡ è¡Œæµ‹è¯•
test_pred_output <- tryCatch(
  pred_wrapper(underlying_model, test_pred_input), # <--- ä½¿ç”¨åº•å±‚æ¨¡å‹æµ‹è¯•
  error = function(e) { paste("pred_wrapper é”™è¯¯:", e$message) }
)
cat("æµ‹è¯•è¾“å‡º (pred_wrapper çš„ç»“æœ):\n")
print(test_pred_output)
cat("æµ‹è¯•è¾“å‡ºç±»å‹:", class(test_pred_output), "\n")
cat("--- SHAP è°ƒè¯•ä¿¡æ¯ ç»“æŸ ---\n\n")


set.seed(42)
shap_values <- NULL
tryCatch({
  # å¼ºåˆ¶è°ƒç”¨é»˜è®¤æ–¹æ³•ä»¥é¿å… S3 è°ƒåº¦é—®é¢˜
  shap_values <- kernelshap:::kernelshap.default( # <--- ä½¿ç”¨ ::: æ˜¾å¼è°ƒç”¨ default æ–¹æ³•
    object = underlying_model,  # <--- ä½¿ç”¨åº•å±‚æ¨¡å‹å¯¹è±¡
    X = explainer_data,        # èƒŒæ™¯æ•°æ® (æ•°å€¼å‹)
    X_pred = eval_data,        # è§£é‡Šæ•°æ® (æ•°å€¼å‹)
    pred_fun = pred_wrapper,   # åŒ…è£…å‡½æ•° (å†…éƒ¨ä¸è½¬æ¢å› å­)
    nsim = 50,                 # å‡å°‘ nsim ä»¥åŠ å¿«é€Ÿåº¦
    parallel = FALSE
  )
}, error = function(e) {
  cat(sprintf("SHAP è®¡ç®—å¤±è´¥: %s\n", e$message))
  cat("è¯·æ£€æŸ¥ pred_wrapper å‡½æ•°æ˜¯å¦æ­£ç¡®å¤„ç†äº†æ¨¡å‹ç±»å‹åŠå…¶é¢„æµ‹è¾“å‡ºï¼Œä»¥åŠè¾“å…¥æ•°æ®æ˜¯å¦ä¸ºæ•°å€¼å‹ã€‚\n")
})


if (!is.null(shap_values)) {
  cat("SHAP å€¼è®¡ç®—å®Œæˆã€‚\n")
  
  # --- 5. åˆ›å»º SHAP å¯è§†åŒ–å¯¹è±¡ ---
  # ç¡®ä¿ X æ˜¯æ•°å€¼å‹çš„ (sex å·²ç»æ˜¯)
  sv <- shapviz(shap_values, X = eval_data)
  
  # --- 6. ç»˜åˆ¶å¹¶ä¿å­˜ SHAP èœ‚çªå›¾ (Beeswarm) ---
  cat("ç”Ÿæˆ SHAP èœ‚çªå›¾...\n")
  
  # è°ƒæ•´ ggsave çš„å®½åº¦ä»¥å®¹çº³æ‰€æœ‰ç‰¹å¾
  plot_width <- 7 + (ncol(eval_data) * 0.1)
  plot_height <- max(5, (ncol(eval_data) * 0.3))
  
  # sv_plot_beeswarm è‡ªåŠ¨è¿”å›ä¸€ä¸ª ggplot å¯¹è±¡
  p_shap_beeswarm <- sv_plot_beeswarm(sv, max_display = 20) + # æœ€å¤šæ˜¾ç¤º20ä¸ªç‰¹å¾
    labs(title = sprintf("SHAP èœ‚çªå›¾ (æ¨¡å‹: %s)", best_model_name)) +
    theme(plot.title = element_text(hjust = 0.5))
  
  ggsave(
    paste0(base_path, "shap_beeswarm_plot.png"),
    plot = p_shap_beeswarm,
    width = plot_width,
    height = plot_height,
    dpi = 300
  )
  
  # --- 7. ç»˜åˆ¶å¹¶ä¿å­˜ SHAP ç‰¹å¾é‡è¦æ€§å›¾ (æ¡å½¢å›¾) ---
  cat("ç”Ÿæˆ SHAP ç‰¹å¾é‡è¦æ€§å›¾...\n")
  p_shap_importance <- sv_plot_importance(sv, max_display = 20) +
    labs(title = sprintf("SHAP ç‰¹å¾é‡è¦æ€§ (æ¨¡å‹: %s)", best_model_name)) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
  
  ggsave(
    paste0(base_path, "shap_importance_plot.png"),
    plot = p_shap_importance,
    width = 10,
    height = 8,
    dpi = 300
  )
  
  cat("âœ“ SHAP å›¾è¡¨å·²ä¿å­˜ã€‚\n")
  print(p_shap_beeswarm)
  print(p_shap_importance)
  
} else {
  cat("ç”±äº SHAP è®¡ç®—å¤±è´¥, è·³è¿‡ SHAP ç»˜å›¾ã€‚\n")
}


cat("\n\n====== è„šæœ¬æ‰§è¡Œå®Œæ¯• ======\n")

